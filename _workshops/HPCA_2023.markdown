---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: default
conference: HPCA
hpca: true
date: 2023-02-17
prettify-conference-date: "February 25, 2023" 
collectionid: 'hpca-2023-pages' 
conference-url: "https://hpca-conf.org/2023/workshop-tutorial/"
canceled: false
---

<div id="toc_container" style="position: absolute" markdown="1">
<p class="toc_title">Table of Contents</p>

- TOC
{:toc}
</div>

### Welcome

To build your own TinyML accelerator and processor during the tutorial, attendees will need to bring a laptop running Ubuntu 18 or 20 with a USB port and CFU Playground installed. See repo installation directions [here](https://cfu-playground.readthedocs.io/en/latest/setup-guide.html). *We will provide the Lattice FPGAs (Option 4b).*

<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vRBA7fvaeUFvxXuPnbeq6tl4tFIxRnMG09-TP7RCk5f6Hd9ZrEGvgijBeEwqOGSGDco3fMEjs7fBUiL/embed?start=false&loop=false&delayms=3000" frameborder="0" width="746" height="449" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

### Demo Video
<iframe src="https://drive.google.com/file/d/1l1eUSqSeUHHzTSWsa8wW87NKzPhfnYuy/preview" width="746" height="449" allow="autoplay"></iframe>

### Overview
We are running a half-day tutorial on TinyML Acceleration at [HPCA 2023](https://hpca-conf.org/2023/workshop-tutorial/") in Montreal!

Embedded FPGAs will be provided for free to in-person attendees to build their own TinyML processor and accelerator during the tutorial! Remote participation at HPCA 2023 is not supported.

### About 
Need for the efficient processing of neural networks has given rise to the development of hardware accelerators. The increased adoption of specialized hardware has highlighted the need for more agile design flows for hardware-software co-design and domain-specific optimizations. We present CFU Playground, a full-stack open-source framework that enables rapid and iterative design and evaluation of machine learning (ML) accelerators for embedded ML systems. Our toolchain provides a completely open-source end-to-end flow for hardware-software co-design on FPGAs and future systems research. This full-stack framework gives the users access to explore experimental and bespoke architectures that are customized and co-optimized for embedded ML. Our rapid, deploy-profile-optimization feedback loop lets ML hardware and software developers achieve significant returns out of a relatively small investment in customization. Using CFU Playground’s design and evaluation loop, we show substantial speedups in just minutes! The soft CPU coupled with the accelerator opens up a new, rich design space between the two components that we explore in an automated fashion using Vizier, a black-box optimization service.

#### What is the goal of the workshop?
- Learn what are the challenges and opportunities for designing TinyML hardware.
- Design and develop model-specific accelerators quickly on FPGAs.
- Get hands-on knowledge on how to build an ML accelerator and perform design space exploration using CFU playground!

#### Who is the audience for this workshop?
New ML accelerators are being announced and released each month for a variety of applications. However, the large cost & complexity associated with designing an accelerator, integrating it into a larger System-on-Chip, and developing its software stack has made it a non-trivial task that is difficult for one to rapidly iterate upon. Attendees will be able to deploy their very own accelerated ML solutions within minutes, empowering them to explore the breadth of opportunity that exists in hardware acceleration. This in conjunction with the relevance and excitement surrounding ML today should welcome people with many different backgrounds and interests in ML, FPGAs, embedded systems, computer architecture, hardware design, and software development. 

#### Scope and Topics 
- Custom Hardware Acceleration on FPGAs
- Tiny Machine Learning (TinyML)
- Open-Source Tools/Frameworks for HW & SW Development (Full-Stack)

### Requirements
To build your own TinyML accelerator and processor during the tutorial, attendees will need to bring a Linux laptop with CFU Playground installed. See installation directions [here](https://cfu-playground.readthedocs.io/en/latest/setup-guide.html). *We will provide the Lattice FPGAs (Option 4b).*

#### Pre-requisites
- Knowledge of computer organization (RISC pipeline, registers, opcodes, etc.)
- Basic experience with HDL (being able to read Verilog) & synthesis concepts for FPGAs
- Familiarity with C and Python
- Familiarity with ML “cycle” (inputs, preprocessing, training, inference, etc.) is helpful but not required

#### Hardware
- For the *tutorial*, or to experiment with CFU-Playground using simulators, none is required.
- To develop on an FPGA, one of the supported FPGA boards is required (or you might be able to add support!)

#### Software
- All software (RISCV toolchain, Symbiflow, etc.) installed in via environment pre-packaged with CFU Playground. 

### Tutorial Schedule
<div>
<table>
<thead>
  <tr>
    <th>Time</th>
    <th>Material/Activity</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1:30 PM</td>
    <td>Welcome &amp; Tiny Machine Learning (TinyML)
    	<ul>
    	<li>Tutorial Overview</li>
    	<li>General survey of the field of TinyML</li>
    	<li>What are the common use cases</li>
    	<li>What kind of models do we run</li>
    	<li>What are the typical resource constraints, challenges, etc.</li>
    	</ul>
    </td>
  </tr>
  <tr>
    <td>2:00 PM</td>
    <td>CFU Playground: Full-Stack Framework for TinyML Acceleration Using HW-SW Co-Design
    	<ul>
    		<li>General overview of CFUs</li>
                <li>Tour of CFU Playground</li>
                <li>End-to-end guide of building an ML Accelerator</li>
    	</ul>
	</td>
  </tr>
  <tr>
    <td>2:50 PM</td>
    <td>Design Space Exploration of CPU vs CFU accelerator
    	<ul>
                <li>Renode and Verilator simulation</li>
                <li>Google's Vizier for Black-Box Search Optimization</li>
                <li>Integration with CFU Playground for DSE</li>
    	</ul>
    </td>
  </tr>
  <tr>
    <td>3:20 PM</td>
    <td>Coffee Break
	</td>
  </tr>
  <tr>
    <td>3:40 PM</td>
    <td>TensorFlow Lite Microcontrollers (TFLM)
    	<ul>
       	<li>What is TF Lite Micro</li>
         <li>TF vs. TF Lite vs TF Lite Micro</li>
         <li>Running TF Lite on-device</li>
    	</ul>
	</td>
  </tr>
  <tr>
    <td>4:10 PM</td>
    <td>Benchmarking of TinyML Systems
    	<ul>
         <li>Importance of benchmarking and challenges of benchmarking TinyML systems</li>
         <li>MLPerf Tiny and it's workloads well suited for CFUs</li>
         <li>CFU Playground for Architects and the Hardware Lottery Problem</li>
         <li>Demo of Profiling/Microbenchmarking support in CFU Playground</li>
    	</ul>
	</td>
  </tr>
  <tr>
    <td>4:40 PM</td>
    <td>Build Your Own Processor (BYOP)
    	<ul>
                <li>Accelerate Your Own TinyML Model</li>
                <li>Case study of model and profiling results provided</li>
                <li>Implement a new instruction in the CFU</li>
                <li>Use the new instruction in a TFLM kernel</li>
                <li>Measure performance speed up</li>
    	</ul>
    </td>
  </tr>
</tbody>
</table>
</div>
